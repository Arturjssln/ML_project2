{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "sys.path.append(\"..\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../../data/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "\n",
    "files = os.listdir(image_dir)\n",
    "n = min(20, len(files)) #load max 5 images\n",
    "\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "n_train = 3 #use 3 images for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Image size = ' + str(imgs[0].shape[0]) + ',' + str(imgs[0].shape[1]))\n",
    "# Show first image and its groundtruth image\n",
    "cimg = concatenate_images(imgs[0], gt_imgs[0])\n",
    "fig1 = plt.figure(figsize=(20, 20))\n",
    "plt.title('Image and groundtruth comparaison')\n",
    "plt.imshow(cimg, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shows patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from input images\n",
    "patch_size = 16 # each patch is 16*16 pixels\n",
    "\n",
    "img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "\n",
    "\n",
    "fign = plt.figure(figsize=(10,10))\n",
    "print(img_patches.shape)\n",
    "image_number=1002\n",
    "cimg = concatenate_images(img_patches[image_number], gt_patches[image_number])\n",
    "plt.title('batch comparaison n 1002')\n",
    "plt.imshow(cimg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply gaussian blur to images\n",
    "from scipy.ndimage import gaussian_filter\n",
    "def convert_gaussian(_sigma, img):\n",
    "    _sigma = 3\n",
    "    gauss_img = gaussian_filter(img, sigma=_sigma)\n",
    "    return gauss_img\n",
    "\n",
    "fig_gauss = plt.figure(figsize=(10,10))\n",
    "gauss_img = convert_gaussian(3, imgs[0])\n",
    "cimg = concatenate_images(imgs[0], gauss_img)\n",
    "plt.figure()\n",
    "plt.title('gaussian with sigma 3')\n",
    "plt.imshow(cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D FFT useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from skimage import color\n",
    "gauss_img_gray = color.rgb2gray(gauss_img)\n",
    "im_fft = fftpack.fft2(gauss_img_gray)\n",
    "print(gauss_img_gray.shape)\n",
    "# Show the results\n",
    "\n",
    "def plot_spectrum(im_fft):\n",
    "    from matplotlib.colors import LogNorm\n",
    "    # A logarithmic colormap\n",
    "    plt.imshow(np.abs(im_fft), norm=LogNorm(vmin=5))\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.figure()\n",
    "plot_spectrum(im_fft)\n",
    "plt.title('Fourier transform')\n",
    "\n",
    "\n",
    "\n",
    "# In the lines following, we'll make a copy of the original spectrum and\n",
    "# truncate coefficients.\n",
    "\n",
    "# Define the fraction of coefficients (in each direction) we keep\n",
    "keep_fraction = 0.1\n",
    "\n",
    "# Call ff a copy of the original transform. Numpy arrays have a copy\n",
    "# method for this purpose.\n",
    "im_fft2 = im_fft.copy()\n",
    "\n",
    "# Set r and c to be the number of rows and columns of the array.\n",
    "r, c = im_fft2.shape\n",
    "\n",
    "# Set to zero all rows with indices between r*keep_fraction and\n",
    "# r*(1-keep_fraction):\n",
    "im_fft2[int(r*keep_fraction):int(r*(1-keep_fraction))] = 0\n",
    "\n",
    "# Similarly with the columns:\n",
    "im_fft2[:, int(c*keep_fraction):int(c*(1-keep_fraction))] = 0\n",
    "\n",
    "plt.figure()\n",
    "plot_spectrum(im_fft2)\n",
    "plt.title('Filtered Spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the denoised image from the filtered spectrum, keep only the\n",
    "# real part for display.\n",
    "im_new = fftpack.ifft2(im_fft2).real\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im_new, plt.cm.gray)\n",
    "plt.title('Reconstructed Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = imgs[0]\n",
    "img = (img*255).astype(np.uint8)#convert to smth opencv can work with\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#edges = cv2.Canny(img,10,20,apertureSize = 3)\n",
    "\n",
    "##autocanny\n",
    "v = np.median(img)\n",
    "sigma = 0.33\n",
    "# apply automatic Canny edge detection using the computed median\n",
    "lower = int(max(0, (1.0 - sigma) * v))\n",
    "upper = int(min(255, (1.0 + sigma) * v))\n",
    "edged = cv2.Canny(img, lower, upper)\n",
    "##end autocanny\n",
    "\n",
    "plt.figure()\n",
    "plt.title('canny edge')\n",
    "plt.imshow(edges)\n",
    "\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 250, None, 0, 0)\n",
    "\n",
    "if lines is not None:\n",
    "    for i in range(0, len(lines)):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "        cv2.line(img, pt1, pt2, (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_number = 12\n",
    "aperture_original = 3\n",
    "aperture_gaussian = 5\n",
    "\n",
    "\n",
    "img_analyse = imgs[img_number]\n",
    "img_analyse = (img_analyse*255).astype(np.uint8)#convert to smth opencv can work with\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(15,15))\n",
    "plt.title('Hough transform test 2')\n",
    "\n",
    "###############################################\n",
    "###############################################\n",
    "axs[0, 0].imshow(img_analyse)\n",
    "axs[0, 0].set_title('original image')\n",
    "\n",
    "#CANNY ORIGINAL\n",
    "\n",
    "edges = cv2.Canny(img_analyse,400,400,apertureSize = aperture_original)\n",
    "axs[0,1].imshow(edges)\n",
    "axs[0,1].set_title('ori canny')\n",
    "\n",
    "#HOUGH ORIGINAL\n",
    "minLineLength = 50\n",
    "maxLineGap = 10\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,1,minLineLength,maxLineGap)\n",
    "for _line in lines:\n",
    "    for x1, y1, x2, y2 in _line:\n",
    "        cv2.line(img_analyse,(x1, y1), (x2, y2),(0,255,0),2)\n",
    "axs[0,2].imshow(img_analyse)\n",
    "axs[0,2].set_title('probabilistic Hough')\n",
    "\n",
    "###############################################\n",
    "###############################################\n",
    "\n",
    "\n",
    "#GAUSS\n",
    "img_analyse = imgs[img_number]\n",
    "img_analyse = (img_analyse*255).astype(np.uint8)#convert to smth opencv can work with\n",
    "\n",
    "gauss_img = convert_gaussian(2, img_analyse)\n",
    "axs[1, 0].imshow(gauss_img)\n",
    "axs[1, 0].set_title('gaussian image')\n",
    "\n",
    "\n",
    "#CANNY Gauss\n",
    "gray_gauss_img = cv2.cvtColor(gauss_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray_gauss_img = (gray_gauss_img*255).astype(np.uint8)#need to convert to 0-255 in order to not lose information\n",
    "edges_gauss = cv2.Canny(gray_gauss_img, 400, 400, apertureSize=aperture_gaussian)\n",
    "axs[1,1].imshow(edges_gauss)\n",
    "axs[1,1].set_title('canny gauss')\n",
    "\n",
    "#HOUGH Gauss\n",
    "minLineLength = 10\n",
    "maxLineGap = 2\n",
    "##HoughLineP(image,rho, theta, threshold, np.array ([ ]), minLineLength=xx, maxLineGap=xx)\n",
    "lines = cv2.HoughLinesP(edges_gauss,1,np.pi/180,20,minLineLength,maxLineGap)\n",
    "for _line in lines:\n",
    "    for x1, y1, x2, y2 in _line:\n",
    "        cv2.line(img_analyse,(x1, y1), (x2, y2),(0,255,0),2)\n",
    "axs[1,2].imshow(img_analyse)\n",
    "axs[1,2].set_title('probabilistic Hough')\n",
    "\n",
    "###############################################\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image_number = 0\n",
    "kernel_size = 5\n",
    "\n",
    "img_in = imgs[image_number]\n",
    "img_in = (img_in*255).astype(np.uint8)#convert to smth opencv can work with\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(img_in,cv2.COLOR_BGR2GRAY)\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 70  # minimum number of pixels making up a line\n",
    "max_line_gap = 20  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(img_in) * 0  # creating a blank to draw lines on\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "print(lines)\n",
    "points = []\n",
    "for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        points.append(((x1 + 0.0, y1 + 0.0), (x2 + 0.0, y2 + 0.0)))\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "\n",
    "lines_edges = cv2.addWeighted(img_in, 0.8, line_image, 1, 0)\n",
    "print(lines_edges.shape)\n",
    "#cv2.imwrite('line_parking.png', lines_edges)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(lines_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import scipy.spatial as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Stored all RGB values of main colors in a array\n",
    "main_colors = [(0,0,0),\n",
    "                  (255,255,255),\n",
    "                  (255,0,0),\n",
    "                  (0,255,0),\n",
    "                  (0,0,255),\n",
    "                  (255,255,0),\n",
    "                  (0,255,255),\n",
    "                  (255,0,255),\n",
    "                  ] \n",
    "\n",
    "image = imgs[0]\n",
    "plt.figure()\n",
    "#convert BGR to RGB image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "\n",
    "h,w,bpp = np.shape(image)\n",
    "\n",
    "#Change colors of each pixel\n",
    "#reference :https://stackoverflow.com/a/48884514/9799700\n",
    "for py in range(0,h):\n",
    "    for px in range(0,w):\n",
    "      ########################\n",
    "      #Used this part to find nearest color \n",
    "      #reference : https://stackoverflow.com/a/22478139/9799700\n",
    "      input_color = (image[py][px][0],image[py][px][1],image[py][px][2])\n",
    "      tree = sp.KDTree(main_colors) \n",
    "      ditsance, result = tree.query(input_color) \n",
    "      nearest_color = main_colors[result]\n",
    "      ###################\n",
    "      \n",
    "      image[py][px][0]=nearest_color[0]\n",
    "      image[py][px][1]=nearest_color[1]\n",
    "      image[py][px][2]=nearest_color[2]\n",
    "\n",
    "# show image\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
